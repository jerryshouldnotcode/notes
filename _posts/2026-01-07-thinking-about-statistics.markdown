---
layout: post
title:  "Statistics, Data, and Acting Under Uncertainty"
date:   2026-01-07 13:03:00
categories: math 
---

![*(image credits to the Oppenheimer film, and imgflip.com)*]({{ "assets\images\9dwaj6.jpg" | relative_url }})

Recently, I’ve been thinking about the way I approach figures in the news and in papers.

For example, here are some recent headlines I’ve found:

.....................

> “For the week ending Dec. 27, the CDC reported that nearly 1 in 10 outpatient visits nationwide — 8.2% — were for flu-like illnesses…” [NBC, Jan. 5, 2026](https://www.nbcnews.com/health/health-news/flu-2026-states-deaths-cdc-symptoms-superflu-rcna251910)

> “NHS data shows almost one in 10 (9.2%) reception-aged children are now living with obesity, while one in five children have tooth decay by the age of five.” [BBC, Jan. 4, 2026](https://www.bbc.com/news/articles/cq5y2vzlyldo)

> “...72% worry the U.S. will become too involved in the South American country, according to a Reuters/Ipsos poll that concluded on Monday.” [Reuters, Jan. 5, 2026](https://www.reuters.com/world/americas/only-33-americans-approve-us-strike-venezuela-reutersipsos-poll-finds-2026-01-05/)

.....................

I think the reason why the “one in X” framing is useful is that it helps audiences better conceptualize probabilities and the chance of an event occurring based on current data. It’s visceral; it’s concrete. But what does that mean to me now? How do I interpret and use these figures?

Probabilities are really interesting to study as a math major, particularly when you’re used to deterministic statements and analytical proofs. Either a system of linear equations has solutions, or it doesn’t. Either a sequence converges or diverges as n goes to infinity. Sometimes, we can find proof that solutions exist for a problem without knowing which one exactly. A lot of that black-and-white thinking breaks down in statistics.



......................

Student: “So if I asked 100 random people from that population right now, about 72 of them would express that sentiment?”

Teacher: “No. You might get 60. You might get 80. You could even get zero.”

Student: “Zero? Then what does ‘72%’ mean?”

Teacher: “It means that over many hypothetical samples, the average proportion would be close to 0.72. Assuming the model is correct.”

Student: “So not this sample. Not the next one. Just… in the long run.”

Teacher: “Right.”

Student: “How many samples does ‘the long run’ take?”

Teacher: “There isn’t a number.”

Student: “So I can’t know ahead of time whether my sample will look like the population.”

Teacher: “Correct.”

Student: “Then what exactly did we learn?”

Teacher: “Uncertainty.”

Student: “I hate this class.”

.....................

Practically speaking, from the third headline, I can do little with the 72%. It doesn’t tell me how many people in a random sample I choose will agree. It doesn’t tell me that the sentiment will hold tomorrow. It doesn’t even tell me what side one person is likely to take. I have to make a distinction between the population, the sample, and the person.

Why does stats feel pedantic at first glance, only to be evasive at the slightest tug? I have come to a humbling conclusion: it was designed to be so. It’s what you get when you make a math tool that does what it’s meant to do, and nothing more.

Statistics has to be rigorous enough to be mathematically useful, and still not collapse when reality doesn’t meet its assumptions. It has to be math constrained by uncertainty. Therefore, good stats ends up in this… uncanny ground where I have to accept the correct answer as the most likely, while respecting its ontological limits, its approximations, and being skeptical about the experimental design. For all its correctness, there are just some things we can’t say confidently with one piece of stat info. But we don’t get to demand absolute clarity from the world when we have to make choices.

It’s very easy for us to overestimate the certainty we need to make decisions. We don’t choose to get flu vaccines because we’re certain we’d contribute to that ten percent of visits. *“Nearly 1 in 10 outpatient visits nationwide…”* implies that getting a doctor’s appointment if we do fall sick may be harder to obtain, and that the system is strained. Factored with our personal risk, the metric becomes the cherry on top - an extra datapoint we use to come to conclusions with high upsides anyway. Statistics is mathematics telling us that we can have agency in a world where things seldom go our way, and yet hope for results. I think there’s an epistemic beauty in that.

The takeaway: probabilities may not be hard figures. They are subject to the way we measure things: categorize, phrase, and define them, and also subject to the circumstances in which their input is collected. But it isn’t any less mathy or coherent (in fact, a ton of math firepower is necessary). It’s just really careful, and our interpretation of it should be as well.
